# 系统崩溃重启恢复场景分析

> 分析日期: 2025-11-23  
> 场景: 任务执行中系统崩溃重启，分析恢复能力与数据丢失风险  
> 状态: **方案讨论（不修改代码）**

---

## 1. 当前架构状态盘点

### 1.1 运行时状态存储位置

| 数据类型 | 存储位置 | 崩溃后状态 | 影响范围 |
|----------|----------|------------|----------|
| **Plan 聚合** | InMemoryPlanRepository (ConcurrentHashMap) | ❌ **完全丢失** | Plan 状态、任务 ID 列表、并发配置 |
| **Task 聚合** | InMemoryTaskRepository (ConcurrentHashMap) | ❌ **完全丢失** | Task 状态、进度、已完成阶段列表、重试策略 |
| **TaskExecutor 运行态** | InMemoryTaskRuntimeRepository | ❌ **完全丢失** | 执行线程引用、心跳调度器、暂停/取消标志 |
| **Checkpoint** | RedisCheckpointRepository (Redis) | ✅ **可恢复** | lastCompletedStageIndex、completedStageNames |
| **领域事件** | Spring 事件总线（内存） | ❌ **完全丢失** | 未发布/未消费的事件 |
| **租户冲突锁** | TenantConflictManager (ConcurrentHashMap) | ❌ **完全丢失** | 租户互斥状态 |
| **线程池** | ExecutorService (JVM 线程) | ❌ **完全中断** | 正在执行的 Stage、异步任务 |

### 1.2 持久化数据

| 数据类型 | 存储位置 | 崩溃后状态 | TTL | 说明 |
|----------|----------|------------|-----|------|
| **Checkpoint** | Redis String | ✅ **保留** | 7天（可配） | 断点可恢复，包含已完成阶段索引和名称 |
| ~~Plan 配置~~ | ❌ 无持久化 | - | - | 外部系统负责保存（假设） |
| ~~Task 配置~~ | ❌ 无持久化 | - | - | TenantDeployConfig 来自外部 |

---

## 2. 崩溃场景分析

### 场景 A：执行中崩溃（Stage 执行到一半）

**执行时间线**：
```
t0: Task 开始执行（PENDING → RUNNING）
t1: Stage-1 完成 → 保存 Checkpoint(lastCompleted=0)
t2: Stage-2 开始执行
t3: 💥 系统崩溃（Stage-2 执行到 60%）
t4: 系统重启
```

**崩溃时状态**：
- ✅ Redis 中有 Checkpoint：`lastCompletedStageIndex=0, completedStageNames=["Stage-1"]`
- ❌ Task 聚合状态丢失：status=RUNNING、currentStage="Stage-2"、pauseRequested=false
- ❌ TaskExecutor 实例丢失：Stage-2 的执行上下文、中间结果
- ❌ 心跳调度器丢失：最后一次 TaskProgressEvent 未发出

**重启后问题**：
1. **聚合无法自动恢复**：
   - InMemoryTaskRepository 为空，无法通过 `taskRepository.find(taskId)` 获取 Task
   - Plan 也丢失，无法知道哪些任务需要恢复

2. **无法判断任务是否在执行**：
   - Checkpoint 存在 → 说明任务曾经执行
   - 但无法判断是"执行中崩溃"还是"已完成但未清理 Checkpoint"

3. **租户锁丢失**：
   - TenantConflictManager 的 `runningTenants` Map 清空
   - 如果多实例场景，其他实例可能认为租户已释放

4. **事件丢失**：
   - Stage-2 开始的 `TaskStageStartedEvent` 未发出
   - 外部监听器无法感知任务状态

---

### 场景 B：Stage 边界崩溃（刚完成 Stage，未进入下一个）

**执行时间线**：
```
t0: Stage-2 执行完成
t1: completeStage() 调用
t2: 保存 Checkpoint(lastCompleted=1)
t3: 💥 系统崩溃（准备进入 Stage-3）
t4: 系统重启
```

**崩溃时状态**：
- ✅ Redis 中有 Checkpoint：`lastCompletedStageIndex=1, completedStageNames=["Stage-1", "Stage-2"]`
- ❌ Task 聚合丢失（同场景 A）
- ✅ Stage-2 已完成，数据一致性较好

**重启后问题**：
- 与场景 A 相同：聚合丢失，无法自动恢复
- 优势：Checkpoint 准确，从 Stage-3 恢复不会重复执行

---

### 场景 C：暂停状态崩溃

**执行时间线**：
```
t0: Task 执行中
t1: 用户调用 pauseTaskByTenant()
t2: Task 设置 pauseRequested=true（内存）
t3: Stage-3 完成，检测到 pauseRequested
t4: applyPauseAtStageBoundary() → status=PAUSED
t5: 保存 Checkpoint(lastCompleted=2)
t6: 💥 系统崩溃
t7: 系统重启
```

**崩溃时状态**：
- ✅ Checkpoint 保存（lastCompleted=2）
- ❌ Task.status=PAUSED 丢失（内存）
- ❌ pauseRequested 标志丢失

**重启后问题**：
- **无法区分"暂停"还是"执行中崩溃"**
- 外部监听器收到过 `TaskPausedEvent`，但重启后聚合状态不一致

---

### 场景 D：Plan 级别崩溃

**执行时间线**：
```
t0: Plan 创建（包含 10 个 Task）
t1: Task-1 ~ Task-3 已启动（RUNNING）
t2: Task-4 ~ Task-10 排队等待（PENDING）
t3: 💥 系统崩溃
t4: 系统重启
```

**崩溃时状态**：
- ✅ Task-1 ~ Task-3 可能有 Checkpoint（如果执行了至少 1 个 Stage）
- ❌ Plan 聚合丢失：taskIds、maxConcurrency、status
- ❌ Task-4 ~ Task-10 的 PENDING 状态丢失
- ❌ Orchestrator 的线程池、Semaphore 丢失

**重启后问题**：
- **无法知道哪些 Task 属于同一个 Plan**
- 无法续接编排逻辑（并发控制、调度策略）

---

## 3. 根本问题总结

### 3.1 核心矛盾

| 问题 | 根因 | 影响 |
|------|------|------|
| **聚合状态易失** | InMemory 存储 | 崩溃后无法重建聚合根 |
| **运行态不可恢复** | TaskExecutor/Orchestrator 在 JVM 堆 | 线程、调度器、标志位全部丢失 |
| **Checkpoint 孤岛** | 仅 Checkpoint 持久化，但无聚合上下文 | 无法判断任务是否需要恢复、从哪里恢复 |
| **Plan-Task 关联丢失** | Plan 不持久化 | 无法恢复 Plan 级编排 |
| **事件不可靠** | 同步发布，无持久化 | 外部系统状态不一致 |

### 3.2 当前架构假设（隐含）

1. **假设 1**：任务执行是"瞬时"或"短期"的，不需要跨实例恢复
2. **假设 2**：外部系统保存 Plan 配置，可以重新提交
3. **假设 3**：事件丢失可接受，监听器有容错机制
4. **假设 4**：单实例部署，无需分布式恢复

---

## 4. 恢复能力评估

### 4.1 自动恢复能力

| 能力 | 当前支持 | 说明 |
|------|----------|------|
| 从 Checkpoint 手动重试 | ⚠️ **部分** | 需要外部系统重新调用 `retryTaskByTenant()`，但 TaskId 已丢失 |
| 自动检测中断任务 | ❌ **不支持** | 重启后无法枚举哪些任务需要恢复 |
| Plan 级恢复 | ❌ **不支持** | Plan 聚合丢失，无法续接 |
| 租户锁自动释放 | ❌ **不支持** | 锁丢失，但也无任务在跑，不影响新任务 |
| 事件补偿 | ❌ **不支持** | 事件丢失，外部状态不一致 |

### 4.2 手动恢复流程

**前提**：外部系统保存了 PlanId、TaskId、TenantId 映射关系。

**步骤**：
1. 外部系统检测到服务重启（心跳中断、健康检查失败）
2. 查询自己的数据库，找到"执行中"的任务列表（假设外部有状态跟踪）
3. 对每个任务：
   - 调用 `DeploymentTaskFacade.retryTaskByTenant(tenantId, fromCheckpoint=true)`
   - 如果 Checkpoint 存在 → 从断点恢复
   - 如果 Checkpoint 不存在 → 从头执行（或报错）
4. 外部系统重新创建 Plan（如果需要编排）

**问题**：
- 需要外部系统"知道"哪些任务在执行中（双写状态）
- TaskId 映射关系需要外部维护
- 无法恢复 Plan 级调度（并发控制、冲突检测）

---

## 5. 潜在风险与影响

### 5.1 数据一致性风险

| 风险 | 场景 | 后果 |
|------|------|------|
| **双重执行** | 崩溃前任务已完成，但 Checkpoint 未删除；重启后外部重试 | Stage 重复执行（如果无幂等性） |
| **部分成功丢失** | Stage-2 完成但未保存 Checkpoint（崩溃在保存前） | 重试时 Stage-2 重复执行 |
| **状态不一致** | 外部监听器收到 `TaskStartedEvent`，但重启后任务丢失 | 外部认为任务在跑，实际已失效 |
| **租户锁泄漏** | 多实例场景，一个实例崩溃未释放锁 | 其他实例无法执行该租户任务（虽然当前是单实例） |

### 5.2 业务影响

| 场景 | 影响 | 严重程度 |
|------|------|----------|
| 蓝绿切换中断 | 租户流量可能处于中间状态（部分 Service 切换） | ⚠️ **高** |
| 健康检查失败 | 切换未完成，但外部认为已完成 | ⚠️ **高** |
| 租户配置不一致 | 部分服务切换，部分未切换 | ⚠️ **中** |
| 事件丢失 | 监控/审计系统数据缺失 | ⚠️ **中** |

---

## 6. 解决方案方向（不实施，仅讨论）

### 方案 A：聚合持久化到 Redis

**思路**：将 Plan/Task 聚合序列化为 JSON 存入 Redis，定期/变更时保存。

**优点**：
- 聚合可恢复，重启后重建内存状态
- Checkpoint 有上下文，可判断任务状态

**缺点**：
- 性能开销：每次状态变更都需要写 Redis
- 一致性问题：聚合与 Checkpoint 两次写入不原子
- 序列化复杂度：聚合包含值对象、事件列表

**适用场景**：长任务、高可用要求

---

### 方案 B：引入任务状态表（外部系统）

**思路**：执行模块只负责执行，状态由外部系统（调用方）维护。

**优点**：
- 执行模块保持轻量（无持久化）
- 外部系统主动轮询/重试，不依赖模块自恢复

**缺点**：
- 双写逻辑：外部需维护任务 ID、状态、Checkpoint 指针
- 恢复延迟：依赖外部轮询间隔
- Plan 级编排无法恢复

**适用场景**：有强外部编排系统（如 K8s CronJob、调度平台）

---

### 方案 C：WAL（Write-Ahead Log）+ 事件溯源

**思路**：所有状态变更写入 WAL（如 Redis Stream / Kafka），重启后回放重建状态。

**优点**：
- 状态完全可恢复
- 事件不丢失（持久化）
- 可审计、可回溯

**缺点**：
- 架构复杂度高（引入事件溯源）
- 回放逻辑复杂（幂等性、顺序性）
- 存储开销大

**适用场景**：金融级高可靠系统

---

### 方案 D：At-Least-Once + 幂等性保障

**思路**：接受崩溃后任务丢失，外部重试时保证 Stage 幂等执行。

**优点**：
- 架构简单，无需持久化聚合
- Checkpoint 仍可跳过已完成 Stage
- 成本低

**缺点**：
- 依赖 Stage 幂等性（健康检查、Redis 写入需设计幂等）
- 可能重复执行部分 Stage
- Plan 级编排无法恢复

**适用场景**：短任务、可接受重试的系统

---

### 方案 E：混合模式（推荐）

**思路**：
1. **核心状态持久化**：Task 聚合关键字段（TaskId、TenantId、PlanId、Status）存 Redis Hash
2. **Checkpoint 增强**：包含 taskStatus、timestamp，可判断是否需要恢复
3. **Plan 轻量持久化**：仅保存 PlanId、TaskIds 映射，重启后重建编排器
4. **事件最终一致**：外部监听器容错，接受短暂不一致

**实施要点**：
- Task 状态变更时同步更新 Redis（SET + Pipeline）
- 重启时扫描 Redis 中 `status=RUNNING` 的任务，自动恢复
- Plan 通过 TaskId 反查恢复（或外部重新提交）

**优点**：
- 平衡复杂度与可靠性
- 支持自动恢复（主要任务）
- 性能开销可控（仅状态写入，非全量聚合）

**缺点**：
- 需要修改仓储实现（Redis 双写）
- 恢复逻辑需新增启动扫描

---

## 7. 当前架构的适用边界

### 7.1 可接受的场景

| 场景 | 说明 |
|------|------|
| **短期任务** | 执行时间 < 1分钟，崩溃概率低 |
| **单实例部署** | 无分布式恢复需求 |
| **可重试系统** | 外部有重试机制，可接受任务丢失 |
| **Stage 幂等** | 重复执行无副作用 |
| **低 SLA 要求** | 99% 可用性即可，非 99.99% |

### 7.2 不适用的场景

| 场景 | 风险 |
|------|------|
| **长任务** | 执行时间 > 10分钟，崩溃概率高，重启成本大 |
| **高 SLA 要求** | 需要自动恢复，不依赖外部重试 |
| **多实例部署** | 租户锁、Plan 编排无法跨实例恢复 |
| **非幂等 Stage** | 重复执行有副作用（如扣费、通知） |
| **审计严格** | 事件丢失不可接受 |

---

## 8. 建议与后续行动

### 8.1 短期建议（当前架构下）

1. **文档化假设**：在架构文档中明确"不支持崩溃自动恢复"
2. **外部容错**：调用方需维护任务状态，检测心跳中断后重试
3. **Checkpoint TTL 缩短**：避免历史断点干扰（如 1天）
4. **Stage 幂等性设计**：所有 Step 实现幂等（健康检查、Redis SET）
5. **监控告警**：实例崩溃后立即告警，人工介入

### 8.2 长期演进（如果需要高可用）

1. **实施方案 E**：Task 状态持久化 + 启动扫描恢复
2. **分布式租户锁**：Redis SET NX + TTL，避免锁泄漏
3. **事件持久化**：引入 Redis Stream / Kafka 存储领域事件
4. **健康检查与续租**：TaskExecutor 定期续租锁，崩溃后自动释放

### 8.3 待决策问题

| 问题 | 选项 | 影响 |
|------|------|------|
| 是否需要自动恢复？ | 是 / 否 | 决定是否持久化聚合 |
| 可接受的恢复时间？ | 秒级 / 分钟级 / 手动 | 决定扫描频率 |
| 事件丢失是否可接受？ | 是 / 否 | 决定是否引入事件持久化 |
| 是否多实例部署？ | 是 / 否 | 决定是否实施分布式锁 |

---

## 9. 总结

**当前架构的恢复能力**：
- ✅ Checkpoint 可恢复，手动重试可跳过已完成 Stage
- ❌ 聚合状态丢失，无法自动恢复
- ❌ Plan 编排丢失，无法续接
- ❌ 事件丢失，外部状态不一致

**核心矛盾**：
- **设计目标**：轻量化执行模块（InMemory）
- **现实需求**：高可用、自动恢复（需持久化）

**适用边界**：
- 当前架构适合**短任务、单实例、外部重试、低 SLA** 场景
- 不适合**长任务、高 SLA、多实例** 场景

**演进方向**：
- 如果需要高可用，推荐**方案 E**（Task 状态持久化 + 启动扫描）
- 如果保持轻量，依赖**外部重试 + Stage 幂等性**（方案 D）

---

> **下一步**：根据业务 SLA 要求，决策是否启动持久化改造（建议先评估任务平均执行时间、崩溃频率）。

